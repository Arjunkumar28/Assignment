<h1> Day-6 Articles </h1> 

<p>
On sixth day internship,I learnt that what is a first generation of computer?. The computer is used to compute, mostly they used for calculations and also used for to process the data and used to store the memory in a device.The first generation computer called as machine level language.

</P> <p>
Now a days mostly computer is used for day today life, A computer is a machine that can be programmed to carry out the sequence of arithmetic or logical operations automatically.

</p> <p>
If we gives the some values in input and it will process and store the memory in a devices called as CPU- Central Processing Unit and it will reveals the final output. 

</p> <p>
In machine level language mostly they used "MORSE CODE", The morse code is the representing letters of the alphabet, numerals and punctuation marks by an arrangement of dots,dashes and spaces, these codes are used to transmitted the morse codes.
</p>

<h2> Data </h2> 

In computing, data is collecting the information that has been translated into a form of efficient for movement or processing.Now a day's computers able to send or receive the data, data is information converted into binary digital 

<h2> Evolution process in computer </h2>	

<ul>  
	<li> Mechanical </li>  
	<li> Electrical </li>
	<li> Electronics </li>
	<li> Quantum </li>
</ul> 

<p>
The mechanical-level language is used in older days,its very hard to use and it has long processor to operate the first generation computers  and day by day its changes to Binary number systems. The Method of mathematical expression which uses only two symbols are  0-Zero and 1-One
The eight bits is equal to the one bytes. A switch is used for ON OFF switch is called as a bit.

</p> <p>
The computer is changes to electrical level into electronics level, In electronics level they used mostly chip-Microprocessor, SOC- System On a Chip.

</p> <p>
Chip- The chip is a Integrated Circuits is called as a IC and its is a electronic circuits. The system-on-a-chip is the silicon chip. Along  with a processor, the SOC usually contains a GPU-Graphics Processor, memory, USB controller,etc...  

</p> <p>
Before days many company created the own binary system, the company like- microsoft,IBM, etc... after that they standardized the binary system. For example small "a" is 97-01100001.

</p>

<h2> DATA Card </h2> 

<p>
A data card is a removable computers component that contains data or is used for data operation. such that data input, data output, data transformation, data transfer and the data card is a electronic card.
</p>

<h2> Clock Speed </h2>

<p>
The clock speed is used for processor and the processor speed for per-second is equal to 2.4GHZ.
</p>

<ol>
	<li> Normally for human we want 20HZ frequency </li>
	<li> In TV they used normally 25HZ frequency </li>
	<li> In computer they used the frequency in 60HZ,120HZ,144HZ </li>
</ol>

<h2> Character sets </h2>

<p> 
They are two types of character sets are availale.
</p> 
<ul>
	<li> ASCII </li>
	<li> UNICODE </li>
</ul>

<p>
ASCII- American Standard Code for Information Interchange. The ASCII character set is a 7-bit set of codes that allows 128 different charactersHowever, an eighth bit was sometimes used as a parity bit for checking for errors during the transmission of dat. That is enough for every upper-case letter, lower-case letter, digit and punctuation mark on most keyboards

</p> <p>
UNICODE- Unicode is a universal character encoding standard that assigns a code to every character and symbol in every language in the world. Since no other encoding standard supports all languages, Unicode is the only encoding standard that ensures that you can retrieve or combine data using any combination of languages. Unicode is required with XML, Java, JavaScript, LDAP, and other web-based technologies. 
</p>

<p> UTF-Unicode Transformation Format. </p>

<ol>
	<li> UTF-8- 8-bit is the most common Unicode format. Characters can use as few as 8 bits, maximising compatibility with ASCII. However, UTF-8 also allows for variable-width encoding expanding to 16, 24, 32, 40, or 48 bits when dealing with larger sets of characters. </li>
	<li> UTF-16- 16-bit, variable-width encoding: can expand to 32 bits. </li>
	<li> UTF-32- 32-bit, fixed-width encoding: each character uses exactly 32 bits. </li> 
</ol>

<h2> Quantum Computing </h2> 

<p>
Quantum computing is an area of computing focused on developing computer technology based on the principles of quantum theory.Quantum computing is very hard to solve certain problems.

</p> <p>
IBM designed quantum computers to solve complex problems that today's most powerful supercomputers cannot solve, and still it is in research. 
</p>

<p>
Mentor gave a problem to solve- The problem was. In computer we should give input as four and six and we should get the final output as ten, we should guide the computer to get the output as ten but computer knows to store and count.We tried the many solution but we can't able to find the correct solution.</p>


